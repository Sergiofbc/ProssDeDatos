{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Un RDD (Resilient Distributed Dataset) es la estructura de datos básica de Apache Spark:\n",
    "Es una colección inmutable de objetos distribuidos entre nodos de un clúster.\n",
    "\n",
    "Sin embargo, los RDD no tienen esquema, es decir, Spark no sabe qué significan sus campos. Para poder usar consultas SQL o funciones de alto nivel, se convierten en DataFrame."
   ],
   "id": "97711509f293154b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Impotar librerías",
   "id": "4b4fadf978dd30a4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-20T03:32:15.050202Z",
     "start_time": "2025-08-20T03:32:15.042949Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Crear SparkSession (punto de entrada para Spark SQL)",
   "id": "345433c9a1561076"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T03:32:16.651083Z",
     "start_time": "2025-08-20T03:32:16.639119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Ejemplos Spark SQL\") \\\n",
    "    .getOrCreate()"
   ],
   "id": "65e613841e7e4489",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Cargar datos externos como DataFrame (JSON)\n",
    "\n",
    "Para el JSON: Spark no acepta un bloque único [...] por defecto, sino un objeto por línea."
   ],
   "id": "57cb71ce6cc11411"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T03:29:49.623487Z",
     "start_time": "2025-08-20T03:29:49.414132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n=== Ejemplo 1: Cargar JSON como DataFrame ===\")\n",
    "df = spark.read.json(\"people.json\")\n",
    "df.show()"
   ],
   "id": "902c7ccebd878361",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ejemplo 1: Cargar JSON como DataFrame ===\n",
      "+---+-------+\n",
      "|age|   name|\n",
      "+---+-------+\n",
      "| 29|  Alice|\n",
      "| 35|    Bob|\n",
      "| 40|Charlie|\n",
      "| 21| Sergio|\n",
      "| 80| Camilo|\n",
      "|  9|Natalia|\n",
      "| 20|  Diego|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Registrar DataFrame como Vista Temporal para consultas SQL y\n",
    "Consultas equivalentes con API de DataFrame"
   ],
   "id": "c7fa86ec9037f02c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T03:25:52.655534Z",
     "start_time": "2025-08-20T03:25:52.340320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n=== Ejemplo 2: Consultar con SQL ===\")\n",
    "df.createOrReplaceTempView(\"people\")\n",
    "result = spark.sql(\"SELECT name, age FROM people WHERE age > 30\")\n",
    "result.show()\n",
    "\n",
    "print(\"\\n=== Ejemplo 3: Consultar con API DataFrame ===\")\n",
    "df.select(\"name\", \"age\").where(col(\"age\") > 30).show()"
   ],
   "id": "11123b46ed8842",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ejemplo 2: Consultar con SQL ===\n",
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|    Bob| 35|\n",
      "|Charlie| 40|\n",
      "| Camilo| 80|\n",
      "+-------+---+\n",
      "\n",
      "\n",
      "=== Ejemplo 3: Consultar con API DataFrame ===\n",
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|    Bob| 35|\n",
      "|Charlie| 40|\n",
      "| Camilo| 80|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Operaciones de Agregación Básicas",
   "id": "d8cbe640cfee916f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T03:38:01.863545Z",
     "start_time": "2025-08-20T03:38:00.443941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n=== Ejemplo 4: Operaciones de Agregación ===\")\n",
    "# Con SQL\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        COUNT(*) as total_personas,\n",
    "        AVG(age) as edad_promedio,\n",
    "        MAX(age) as edad_maxima,\n",
    "        MIN(age) as edad_minima\n",
    "    FROM people\n",
    "\"\"\").show()\n",
    "\n",
    "# Con DataFrame API\n",
    "from pyspark.sql.functions import count, avg, max, min\n",
    "df.agg(\n",
    "    count(\"*\").alias(\"total_personas\"),\n",
    "    avg(\"age\").alias(\"edad_promedio\"),\n",
    "    max(\"age\").alias(\"edad_maxima\"),\n",
    "    min(\"age\").alias(\"edad_minima\")\n",
    ").show()"
   ],
   "id": "23f8b3ac926d8ca7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ejemplo 4: Operaciones de Agregación ===\n",
      "+--------------+-----------------+-----------+-----------+\n",
      "|total_personas|    edad_promedio|edad_maxima|edad_minima|\n",
      "+--------------+-----------------+-----------+-----------+\n",
      "|             7|33.42857142857143|         80|          9|\n",
      "+--------------+-----------------+-----------+-----------+\n",
      "\n",
      "+--------------+-----------------+-----------+-----------+\n",
      "|total_personas|    edad_promedio|edad_maxima|edad_minima|\n",
      "+--------------+-----------------+-----------+-----------+\n",
      "|             7|33.42857142857143|         80|          9|\n",
      "+--------------+-----------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Agrupación y Filtrado",
   "id": "9ac122b1112badce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T03:39:25.691432Z",
     "start_time": "2025-08-20T03:39:24.432554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n=== Ejemplo 5: Agrupación por Rangos de Edad ===\")\n",
    "# Con SQL\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        CASE\n",
    "            WHEN age < 18 THEN 'Menor de edad'\n",
    "            WHEN age BETWEEN 18 AND 30 THEN 'Joven'\n",
    "            WHEN age BETWEEN 31 AND 50 THEN 'Adulto'\n",
    "            ELSE 'Mayor'\n",
    "        END as grupo_edad,\n",
    "        COUNT(*) as cantidad,\n",
    "        AVG(age) as edad_promedio\n",
    "    FROM people\n",
    "    GROUP BY grupo_edad\n",
    "    ORDER BY cantidad DESC\n",
    "\"\"\").show()\n",
    "\n",
    "# Con DataFrame API\n",
    "from pyspark.sql.functions import when\n",
    "df.withColumn(\"grupo_edad\",\n",
    "    when(col(\"age\") < 18, \"Menor de edad\")\n",
    "    .when((col(\"age\") >= 18) & (col(\"age\") <= 30), \"Joven\")\n",
    "    .when((col(\"age\") > 30) & (col(\"age\") <= 50), \"Adulto\")\n",
    "    .otherwise(\"Mayor\")\n",
    ").groupBy(\"grupo_edad\").agg(\n",
    "    count(\"*\").alias(\"cantidad\"),\n",
    "    avg(\"age\").alias(\"edad_promedio\")\n",
    ").orderBy(col(\"cantidad\").desc()).show()"
   ],
   "id": "b8a6c525d4daf684",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ejemplo 5: Agrupación por Rangos de Edad ===\n",
      "+-------------+--------+------------------+\n",
      "|   grupo_edad|cantidad|     edad_promedio|\n",
      "+-------------+--------+------------------+\n",
      "|        Joven|       3|23.333333333333332|\n",
      "|       Adulto|       2|              37.5|\n",
      "|        Mayor|       1|              80.0|\n",
      "|Menor de edad|       1|               9.0|\n",
      "+-------------+--------+------------------+\n",
      "\n",
      "+-------------+--------+------------------+\n",
      "|   grupo_edad|cantidad|     edad_promedio|\n",
      "+-------------+--------+------------------+\n",
      "|        Joven|       3|23.333333333333332|\n",
      "|       Adulto|       2|              37.5|\n",
      "|        Mayor|       1|              80.0|\n",
      "|Menor de edad|       1|               9.0|\n",
      "+-------------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
